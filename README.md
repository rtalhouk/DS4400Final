# DS4400Final

This is a project for identifying American Sign Language characters in images using different machine learning 
techniques. 

## Setup


To get started, you'll need a Kaggle API key. This will be used to download the dataset, and can be retrieved
from under your Kaggle account settings. 

__For the programs that are run locally (e.g. Logistic Regression and SVM), perform the following steps.__

- Place the Kaggle API key JSON file at `~/.kaggle/kaggle.json`. 
- You should create a venv, activate it, and install the project requirements by running what's in the code
block below

```shell
# Sets up your venv and requirements
python -m venv ./venv
source venv/bin/activate # For Unix systems. Might vary slightly between OSs or for Windows.
pip install -r requirements.txt

# Downloads the 'strict' dataset
kaggle datasets download grassknoted/asl-alphabet
unzip asl-alphabet.zip -d ./images/
rm asl-alphabet.zip
```

  - If you want to run training with the external dataset too (the 'full' dataset), run the following:
```shell
kaggle datasets download danrasband/asl-alphabet-test
unzip asl-alphabet-test.zip -d ./test-images/
rm asl-alphabet-test.zip
```
  - Using a Python interpreter, also run this:
```python
import os
for letter in os.scandir("./test-images/asl-alphabet-test/"):
    for entry in os.scandir(letter.path):
        os.rename(entry.path, f"./images/asl_alphabet_train/asl_alphabet_train/{letter.name}/{entry.name}")
```

- You're all set!

__For the programs that are run on Google Colab (e.g. Feed Forward Neural Network and Convolutional Neural Network),
perform the following steps.__

- Upload the ipynb file for the model to Google Colab.
- Run each of the cells.
  - The cells won't continue until you also upload your `kaggle.json` file, since it is required for downloading the 
  dataset.
- You're all set!

## ML Models

### Logistic Regression

__All custom Logistic Regression files mentioned in this section are in 
the logistic_regression/ directory.__

Running the LogisticRegression.py file or importing the `train_lr_model()` function from
the same file will train a logistic regression using the dataset at ./images/ and save
it to the file 'log_reg_theta.pkl'. For later use, the function 
`load_theta(<path_to_pickle>)` from the LogisticRegression.py file will return the saved
model.

Graphics are generated by running the graphics.py file. This requires the following four
files, but can be edited if you're only using one.
- `lr_grid_search_results_strict.csv`: The results of `GridSearchCV` for the strict dataset
- `lr_grid_search_results_full.csv`: The results of `GridSearchCV` for the full dataset
- `log_reg_theta_strict.pkl`: The saved best-result from `GridSearchCV` for the strict dataset
- `log_reg_theta_full.pkl`: The saved best-result from `GridSearchCV` for the full dataset

The strict and full datasets refer to the dataset used for training. 
- __Strict__: The dataset consisting of the main dataset (the first one downloaded in 
  the setup instructions)
- __Full__: The dataset consisting of the main dataset, as well as the external testing 
  dataset (the first _AND_ second one downloaded in the setup instructions)

### Support Vector Machine

### Feed Forward Neural Network (FFNN)

Note: Many of the FFNN functions come from logistic_regression/ImageLoader.py or 
logistic_regression/graphics.py.

__All files mentioned in this section are in the feed_forward/ directory.__

Similarly to the Logistic Regression section above, the _strict_ and _full_ naming schema
carries over in the filenames: \*_strict\* and \*_full\*. 

>The strict and full datasets refer to the dataset used for training.
>- __Strict__: The dataset consisting of the main dataset (the first one downloaded in
   the setup instructions)
>- __Full__: The dataset consisting of the main dataset, as well as the external testing
   dataset (the first _AND_ second one downloaded in the setup instructions)

- FFNN_strict.ipynb is the FFNN setup and training/testing code for the strict dataset, and
  results_strict.csv is a csv file containing the histories and results of each model trained.
- FFNN_full.ipynb is the FFNN setup and training/testing code for the full dataset, and
  results_full.csv is a csv file containing the histories and results of each model trained.

### Convolutional Neural Network